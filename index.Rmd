---
title: "Practical Machine Learning Course Project"
author: "Ramesh Alagesan"
date: "December 24, 2015"
output: html_document
---

Loading required packages

```{r, echo=FALSE}
library(caret)
library(AppliedPredictiveModeling)
```
# Pre-Procssing
  * Loading traning and testing dataset
  * na.string imputed for values "NA",  "#DIV/0!" or  ""
  * removed columns such as id, name, time
  * removed near zero variance


```{r, echo=FALSE}
# data cleaning -- replace na.stings for data with "NA", "DIV/0!", "" to load csv file into data object
pml_training_data <- read.csv("pml-training.csv",header=TRUE, sep=",", na.strings = c("NA", "#DIV/0!", ""))
pml_testing_data <- read.csv("pml-testing.csv", header=TRUE, sep=",", na.strings = c("NA", "#DIV/0!", ""))
```
verify the data dimentions
```{r}
dim(pml_training_data)
```

 removed columns such as id, name, time
 
```{r}
pml_training_data <- pml_training_data[,7:160]
pml_testing_data <-pml_testing_data[,7:160]
```
Data-split bhy train and validation 
```{r}
inTrain = createDataPartition(pml_training_data$classe,p=0.7,list=FALSE)
training = pml_training_data[ inTrain,]
validation = pml_training_data[-inTrain,]
```

remove These variables have zero variances:


```{r}
nzv <- nearZeroVar(training)
filtereddata <- training[, -nzv]
dim(filtereddata)
```

removed columns that are more than half rows were NA

```{r}
filtereddata <- filtereddata[ , -which( colSums(is.na(filtereddata)) > nrow(filtereddata)/2 ) ]
dim(filtereddata)
```

creating feature plots to validate the variance 
``` {r}
featurePlot(x=filtereddata[,c("classe","roll_belt","pitch_belt","yaw_belt","total_accel_belt" )],y = filtereddata$classe,plot="pairs")
featurePlot(x=filtereddata[,c("classe","roll_arm","pitch_arm","yaw_arm","total_accel_arm" )],y = filtereddata$classe,plot="pairs")
```

both featurepolts shows there were variablity and no skewness, so transformation not required
#pre-process - imputation by center and scale
```{r}
filtereddata$classe <- factor(filtereddata$classe)
preProcValues <- preProcess(filtereddata, method = c("center", "scale"))
filtereddata1<-predict(preProcValues,filtereddata)
Train_sample<-createDataPartition(y=filtereddata$classe,p=0.1,list=FALSE)
SampleTrain<-filtereddata[Train_sample,]

```
Train model with random forest , used cross-validation and set allowParallel to optimized computational speed, and i used 5 fold/tree forf this model

```{r TrainRF, cache=TRUE}
# apply random forest
modFit <- train(classe~ .,data=SampleTrain,method="rf",trControl=trainControl(method="cv",number=5), prox=TRUE,allowParallel=TRUE)
train_result <- predict(modFit,Train_sample)
table(train_result, Train_sample$classe)
print(modFit)
```
#Model validation and accuracy
```{r}
validation_result <- predict(modFit,validation)
table(validation_result, validation$classe)
validation_result$correct<- validation_result == validation$classe
accuracy <- sum(validation_result$correct)/length(validation_result)
accuracy
```
Accuracy is 0.95 and which is very good. Let is apply this model to our sample test data

# apply prediction to sample test set

```{r}
test_result <- predict(modFit,pml_testing_data)
print(test_result)

```
#Make results file for submission
```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(test_result)


